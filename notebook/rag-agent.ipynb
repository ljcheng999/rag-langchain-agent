{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02724ce9",
   "metadata": {},
   "source": [
    "# Pre-requisites (optional but recommended)\n",
    "Only do the first step if you have never created a virtual environment for this repository. Otherwise, make sure that the Python Kernel that you selected is from your venv/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbaa661",
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ../venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0bd91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.11\n",
      "/Users/jcheng/Documents/ljcheng/ml/learning/repos/rag-langchain-agent/venv/bin/python3\n"
     ]
    }
   ],
   "source": [
    "! python3 -V\n",
    "! which python3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901a07ea",
   "metadata": {},
   "source": [
    "# Topics Covered:\n",
    "- LangChain LLM Basics\n",
    "- LLM Invocation\n",
    "- LLM with Tools\n",
    "- Structured Output from LLM\n",
    "- Basic LangGraph Chatbot\n",
    "- Adding Memory to the Chatbot\n",
    "- LangGraph Agent with Tools\n",
    "- LangGraph RAG Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd5b3ec",
   "metadata": {},
   "source": [
    "### Part 1: Environment and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4329bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install -q --upgrade pip\n",
    "! pip3 install -qU langchain langchain-openai langchain-community langchain-core python-dotenv python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "831f61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load all environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "langchain_endpoint = os.getenv('LANGCHAIN_ENDPOINT')\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "## LLM\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if(not os.getenv('LANGCHAIN_API_KEY')):\n",
    "  raise KeyError(\"set LANGCHAIN_API_KEY\")\n",
    "if(not os.getenv('OPENAI_API_KEY')):\n",
    "  raise KeyError(\"set OPENAI_API_KEY\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c900c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "00dbb8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning is a type of artificial intelligence that enables computers to learn from data and improve their performance on tasks without being explicitly programmed. It involves training algorithms to recognize patterns and make predictions or decisions based on new input.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 31, 'total_tokens': 74, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_75546bd1a7', 'id': 'chatcmpl-D68QcoTkKjeu6d1OvUOQ4zZ61PFwG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c315d-819d-7e70-8cb6-2d0b3fc48688-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 31, 'output_tokens': 43, 'total_tokens': 74, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "# Using messages for more control\n",
    "messages = [\n",
    "  SystemMessage(content=\"You are a helpful AI assistant that explains complex topics simply.\"),\n",
    "  HumanMessage(content=\"Explain machine learning in 2 sentences.\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c8495",
   "metadata": {},
   "source": [
    "# LLM with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b9e76a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Free to use, refer other infor here: https://docs.langchain.com/oss/python/integrations/tools/google_serper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f8f8ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 freeze > ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e699a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "## https://docs.langchain.com/oss/python/integrations/tools/google_serper\n",
    "\n",
    "search = GoogleSerperAPIWrapper() # Initialize an instance before the decorator tool under internet_serper_search()\n",
    "# search = GoogleSerperAPIWrapper(type=\"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5e0dcedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Calculator Tool:\n",
      "Response: \n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "  \"\"\"Calculate mathematical expressions. Use this for any math calculations.\"\"\"\n",
    "  try:\n",
    "    result = eval(expression)\n",
    "    return f\"The result of {expression} is {result}\"\n",
    "  except Exception as e:\n",
    "    return f\"Error calculating {expression}: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def internet_serper_search(query: str) -> str:\n",
    "  \"\"\"Useful for when you need to ask with search.\"\"\"\n",
    "  return search.run(query)\n",
    "\n",
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools([calculator, internet_serper_search])\n",
    "\n",
    "# Test the calculator tool\n",
    "print(\"Testing Calculator Tool:\")\n",
    "response = llm_with_tools.invoke(\"What's 25 * 4 + 17?\")\n",
    "print(f\"Response: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b1d43",
   "metadata": {},
   "source": [
    "LLM decided to use the calculator tool instead of the search_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a1aec3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'calculator',\n",
       "  'args': {'expression': '25 * 4 + 17'},\n",
       "  'id': 'call_lLvH1Cy9f211eZkMjig9DusJ',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n",
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9cd2c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map tool names to tool objects for dynamic execution\n",
    "tool_map = {\n",
    "  'calculator': calculator,\n",
    "  'internet_serper_search': internet_serper_search,\n",
    "}\n",
    "\n",
    "def handle_tool_calls(response, tool_map):\n",
    "  \"\"\"Executes all tool calls in the LLM response using the tool_map.\"\"\"\n",
    "  if not getattr(response, 'tool_calls', None):\n",
    "    return\n",
    "\n",
    "  print(f\"Tool calls requested: {len(response.tool_calls)}\")\n",
    "  for tool_call in response.tool_calls:\n",
    "    tool_name = tool_call['name']\n",
    "    args = tool_call['args']\n",
    "    print(f\"Tool: {tool_name}\")\n",
    "    print(f\"Args: {args}\")\n",
    "\n",
    "    tool = tool_map.get(tool_name)\n",
    "    if tool:\n",
    "      result = tool.invoke(args)\n",
    "      # Print first 200 chars for long responses (e.g., search)\n",
    "      preview = result[:200] + \"...\" if isinstance(result, str) and len(result) > 200 else result\n",
    "      print(f\"Tool result: {preview}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c48e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What's 25 * 4 + 17?\n",
      "Response: \n",
      "Tool calls requested: 1\n",
      "Tool: calculator\n",
      "Args: {'expression': '25 * 4 + 17'}\n",
      "tool:  name='calculator' description='Calculate mathematical expressions. Use this for any math calculations.' args_schema=<class 'langchain_core.utils.pydantic.calculator'> func=<function calculator at 0x1111f3240>\n",
      "Tool result: The result of 25 * 4 + 17 is 117\n",
      "\n",
      "\n",
      "Query: Search for recent news about artificial intelligence\n",
      "Response: \n",
      "Tool calls requested: 1\n",
      "Tool: internet_serper_search\n",
      "Args: {'query': 'recent news about artificial intelligence'}\n",
      "tool:  name='internet_serper_search' description='Useful for when you need to ask with search.' args_schema=<class 'langchain_core.utils.pydantic.internet_serper_search'> func=<function internet_serper_search at 0x1111f3b00>\n",
      "Tool result: AI News delivers the latest updates in artificial intelligence, machine learning, deep learning, enterprise AI, and emerging tech worldwide. The World's First Viral AI Assistant Has Arrived, and Thing...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_llm_tool(query):\n",
    "  print(f\"Query: {query}\")\n",
    "  response = llm_with_tools.invoke(query)\n",
    "  print(f\"Response: {getattr(response, 'content', response)}\")\n",
    "  handle_tool_calls(response, tool_map)\n",
    "  print(\"\\n\")\n",
    "\n",
    "test_llm_tool(\"What's 25 * 4 + 17?\")\n",
    "test_llm_tool(\"Search for recent news about artificial intelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de901e6",
   "metadata": {},
   "source": [
    "# STRUCTURED OUTPUT FROM LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b76567db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Structured Output - Person Info:\n",
      "Name: John Smith\n",
      "Age: 35\n",
      "Occupation: Software engineer\n",
      "Skills: machine learning, Python programming, cloud architecture\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class PersonInfo(BaseModel):\n",
    "  \"\"\"Information about a person\"\"\"\n",
    "  name: str = Field(description=\"Full name of the person\")\n",
    "  age: Optional[int] = Field(description=\"Age of the person\")\n",
    "  occupation: str = Field(description=\"Person's job or profession\")\n",
    "  skills: List[str] = Field(description=\"List of skills or expertise\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(PersonInfo)\n",
    "\n",
    "# Test with person information\n",
    "print(\"Testing Structured Output - Person Info:\")\n",
    "person_prompt = \"\"\"\n",
    "Extract information about this person:\n",
    "\"John Smith is a 35-year-old software engineer who works at Google.\n",
    "He specializes in machine learning, Python programming, and cloud architecture.\n",
    "John has been working in tech for over 10 years and is passionate about AI research.\"\n",
    "\"\"\"\n",
    "\n",
    "person_result = structured_llm.invoke(person_prompt)\n",
    "print(f\"Name: {person_result.name}\")\n",
    "print(f\"Age: {person_result.age}\")\n",
    "print(f\"Occupation: {person_result.occupation}\")\n",
    "print(f\"Skills: {', '.join(person_result.skills)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d41f85b",
   "metadata": {},
   "source": [
    "# Part 2: Basic LangGraph Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9c69a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -qU langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b27d646",
   "metadata": {},
   "source": [
    "# LangGragh State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f0d7e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e00535ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "  \"\"\"State for our chatbot - this holds the conversation history\"\"\"\n",
    "  # The add_messages function handles appending new messages to the conversation\n",
    "  messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b523cb27",
   "metadata": {},
   "source": [
    "# CREATING THE CHATBOT NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb3f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_node(state: State) -> State:\n",
    "  \"\"\"\n",
    "  The main chatbot node that processes messages and generates responses\n",
    "  \"\"\"\n",
    "  print(f\"Processing {len(state['messages'])} messages\")\n",
    "\n",
    "  # Get the response from the LLM\n",
    "  response = llm.invoke(state[\"messages\"])\n",
    "\n",
    "  # Return the updated state with the new response\n",
    "  return {\"messages\": [response]}\n",
    "\n",
    "print(\"Chatbot node function created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
